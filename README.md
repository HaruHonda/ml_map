# ml_map
<img width="800" src="https://user-images.githubusercontent.com/60038634/138719935-d4cf8094-9cc3-4afd-ace5-aa6a8b134af3.png" alt="エビフライトライアングル" title="サンプル">

### Implemented algorithms listed on ml-map (scikit-learn algorithm cheat-sheet)  
### 1.Regression 
  #### 1.1. [SGD Regression](https://github.com/HaruHonda/ml_map/blob/main/algorithms/1.1.%20SGD%20Regression) 
  #### 1.2. [LASSO & ElasticNet Regression](https://github.com/HaruHonda/ml_map/blob/main/algorithms/1.2.%20LASSO%20%26%20ElasticNet%20Regression)
  #### 1.3. [RIDGE Regression & SVR (Support Vector Regression: Kernel='linear')](https://github.com/HaruHonda/ml_map/tree/main/algorithms/1.2.%20LASSO%20%26%20ElasticNet%20Regression) 
  #### 1.4. [SVR (Support Vector Regression: Kernel='rbf') & Ensemble Regressors](https://github.com/HaruHonda/ml_map/tree/main/algorithms/1.4.%20SVR%20(Support%20Vector%20Regression)%20%26%20Ensemble%20Regressors)

### Supervised learning 
### 2.Classification
  #### 2.1. Linear SVC (Support Vector Classifier: Support Vector Machine without Kernel)
  #### 2.2. SGD Classfier
  #### 2.3. Kernel Approximation　(Non-linear identification required)
  #### 2.4. Naive Bayes
  #### 2.5. K-Neighbors Classifier
  #### 2.6. SVC (Support Vector Classifier: Kernel Support Vector Machine)　& ENSEMBLE Classifiers　

### 3.Clustering
  #### 3.1. MeanShift
  #### 3.2. VBGMM　(Variational Bayesian Gaussian Mixture Model)
  #### 3.3. KMeans
  #### 3.4. MiniBatch KMeans
  #### 3.5. Spectral Clustering
  #### 3.6. GMM　　(Gaussian Mixture Model)

### 4.Dimentionality Reduction
  #### 4.1. Randomized PCA
  #### 4.2. Isomap
  #### 4.3. Spectral Embedding
  #### 4.4. LLE
  #### 4.5. Kernel approximation　　

### Other methods ###
#### Linear & Logistic Regression
#### Decision Tree & Random Forest　
#### Neural Network(Autoencoder, Constrained Boltzmann Machine, Deep Belief Network)
